import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import os

# =================  Config =================
CSV_FILE_PATH = 'data/station_407204_3months.csv'
MODEL_PATH = 'checkpoint/champion_model.pth'
NUM_LANES = 4
INTERVAL_MINUTES = 5
HORIZON = 6

# ç‰©ç†å‚æ•° (fdå›¾è¯»å›¾)
VF = 62.06
KC = 87.65
KJ = 600.0
CAPACITY = 5439.34
# ============================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# --- 1. æ¨¡åž‹åŸºå»º (same as before) ---
class MultiBranchLSTM(nn.Module):
    def __init__(self, hidden_size=64, output_size=1):
        super(MultiBranchLSTM, self).__init__()
        self.lstm_recent = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)
        self.lstm_day = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)
        self.lstm_week = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)
        self.fusion_net = nn.Sequential(
            nn.Linear(hidden_size * 3, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, output_size)
        )

    def forward(self, x_rec, x_day, x_wk):
        _, (h_rec, _) = self.lstm_recent(x_rec)
        _, (h_day, _) = self.lstm_day(x_day)
        _, (h_wk, _) = self.lstm_week(x_wk)
        combined = torch.cat((h_rec.squeeze(0), h_day.squeeze(0), h_wk.squeeze(0)), dim=1)
        return self.fusion_net(combined)


def create_multi_branch_dataset_simple(data_flow, timestamps, len_recent=12, len_period=24, horizon=6):
    X_rec, X_day, X_wk, Y_times = [], [], [], []
    LAG_DAY, LAG_WEEK = 288, 2016
    half_period = len_period // 2
    start_idx = LAG_WEEK + half_period
    end_idx = len(data_flow) - horizon - 3

    for i in range(start_idx, end_idx):
        rec_seq = data_flow[i - len_recent + 1: i + 1, 0]
        day_center = i - LAG_DAY
        day_seq = data_flow[day_center - half_period: day_center + half_period, 0]
        wk_center = i - LAG_WEEK
        wk_seq = data_flow[wk_center - half_period: wk_center + half_period, 0]

        if len(rec_seq) == len_recent and len(day_seq) == len_period and len(wk_seq) == len_period:
            X_rec.append(rec_seq)
            X_day.append(day_seq)
            X_wk.append(wk_seq)
            Y_times.append(timestamps[i])

    return np.array(X_rec), np.array(X_day), np.array(X_wk), np.array(Y_times)


def expected_speed_from_fd(predicted_hourly_flow):
    q = min(predicted_hourly_flow, CAPACITY - 0.1)
    w = CAPACITY / (KJ - KC)
    k_congested = KJ - q / w
    v_congested = q / k_congested

    if q > CAPACITY * 0.80:  # æ‹¥å µé˜ˆå€¼è®¾å®šä¸º 80% å®¹é‡
        return v_congested
    return VF


# --- 2. æ ¸å¿ƒä¸šåŠ¡ä¸Žå…¨åœºæ™¯é‡‡æ ·å¼•æ“Ž ---
def generate_business_dashboard():
    print("ðŸš¦ å¯åŠ¨æ™ºèƒ½å¯¼èˆªè°ƒåº¦å¼•æ“Ž (å¯»æ‰¾å…¨ä¸šåŠ¡åœºæ™¯æ ·æœ¬)... ðŸš¦\n")

    df = pd.read_csv(CSV_FILE_PATH)
    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    df.sort_values('Timestamp', inplace=True)

    raw_flow = df['Flow'].values.reshape(-1, 1)
    timestamps = df['Timestamp'].values
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_flow = scaler.fit_transform(raw_flow)

    X_rec, X_day, X_wk, Y_times = create_multi_branch_dataset_simple(scaled_flow, timestamps, horizon=HORIZON)

    model = MultiBranchLSTM(hidden_size=64).to(device)
    model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))  # ä¿®å¤äº†å®‰å…¨è­¦å‘Š
    model.eval()

    # å»ºç«‹ä¸‰ä¸ªä¸šåŠ¡åˆ†æ”¯çš„å­˜å‚¨å­—å…¸
    scenarios = {
        'A_Shift_Success': None,  # é”™å³°æžä½³
        'B_Persistent_Jam': None,  # æ‹¥å µæ­»é”
        'C_Free_Flow': None  # ç•…é€šæ— é˜»
    }

    # éåŽ†æ•°æ®é›†ï¼Œç›´åˆ°æ‰¾é½ä¸‰ä¸ªåœºæ™¯
    for i in range(len(X_rec)):
        if all(v is not None for v in scenarios.values()):
            break  # æ‰¾é½äº†å°±æå‰ç»“æŸ

        current_time = pd.Timestamp(Y_times[i])

        # 1. é¢„æµ‹å½“ä¸‹å‡ºå‘
        t_rec = torch.from_numpy(X_rec[i:i + 1]).float().unsqueeze(2).to(device)
        t_day = torch.from_numpy(X_day[i:i + 1]).float().unsqueeze(2).to(device)
        t_wk = torch.from_numpy(X_wk[i:i + 1]).float().unsqueeze(2).to(device)

        with torch.no_grad():
            pred_delta = model(t_rec, t_day, t_wk).cpu().numpy()
        pred_section_flow = (scaler.inverse_transform(t_rec[:, -1, 0].cpu().numpy().reshape(-1, 1) + pred_delta)[0][
                                 0] / NUM_LANES) * NUM_LANES * 12
        speed_now = expected_speed_from_fd(pred_section_flow)

        # 2. é¢„æµ‹æŽ¨è¿Ÿ 15 åˆ†é’Ÿ
        t_rec_d = torch.from_numpy(X_rec[i + 3:i + 4]).float().unsqueeze(2).to(device)
        t_day_d = torch.from_numpy(X_day[i + 3:i + 4]).float().unsqueeze(2).to(device)
        t_wk_d = torch.from_numpy(X_wk[i + 3:i + 4]).float().unsqueeze(2).to(device)

        with torch.no_grad():
            pred_delta_d = model(t_rec_d, t_day_d, t_wk_d).cpu().numpy()
        pred_section_flow_d = (scaler.inverse_transform(t_rec_d[:, -1, 0].cpu().numpy().reshape(-1, 1) + pred_delta_d)[
                                   0][0] / NUM_LANES) * NUM_LANES * 12
        speed_delayed = expected_speed_from_fd(pred_section_flow_d)

        # 3. ä¸šåŠ¡åˆ†æ”¯å½’ç±»é€»è¾‘
        data_pack = (current_time, pred_section_flow, speed_now, pred_section_flow_d, speed_delayed)

        if pred_section_flow > CAPACITY * 0.80:
            if speed_delayed > speed_now + 5 and scenarios['A_Shift_Success'] is None:
                scenarios['A_Shift_Success'] = data_pack
            elif speed_delayed <= speed_now + 5 and scenarios['B_Persistent_Jam'] is None:
                scenarios['B_Persistent_Jam'] = data_pack
        else:
            if scenarios['C_Free_Flow'] is None:
                scenarios['C_Free_Flow'] = data_pack

    # --- ç»“æžœæŠ¥å‘Š ---
    print("### ðŸš¦ LSTM ç»“åˆç‰©ç†è§„å¾‹çš„æ™ºèƒ½å‡ºè¡Œè°ƒåº¦é¢„æµ‹ (Predictive Departure Scheduling)\n")
    print(
        "é€šè¿‡å°† LSTM çš„æ—¶åºé¢„æµ‹ç»“æžœè¾“å…¥ **Newell ä¸‰è§’å½¢åŸºæœ¬å›¾ (Triangular FD)**ï¼Œç³»ç»Ÿèƒ½å¤Ÿåœ¨æœªæ¥ 30 åˆ†é’Ÿé¢„åˆ¤é“è·¯æ˜¯å¦é­é‡æ‹¥å µï¼ˆå®¹é‡ä¸‹é™ï¼‰ï¼Œå¹¶é’ˆå¯¹ä¸åŒæƒ…å†µè‡ªåŠ¨ç»™å‡ºé”™å³°è°ƒåº¦å»ºè®®ã€‚\n")

    titles = [
        ("âœ… åœºæ™¯ Aï¼šé”™å³°æ•ˆç›Šæ˜¾è‘— (Shift Recommended)", 'A_Shift_Success'),
        ("âŒ åœºæ™¯ Bï¼šæ‹¥å µæŒç»­æ­»é” (Persistent Congestion)", 'B_Persistent_Jam'),
        ("ðŸŸ¢ åœºæ™¯ Cï¼šå…¨è·¯æ®µç•…é€šæ— é˜» (Free Flow)", 'C_Free_Flow')
    ]

    for title, key in titles:
        data = scenarios[key]
        if data:
            curr_t, flow1, spd1, flow2, spd2 = data
            print(f"**{title}**")
            print(f"- ðŸ•’ æŸ¥è¯¢æ—¶åˆ»ï¼š`{curr_t.strftime('%Y-%m-%d %H:%M')}`")
            print(f"- ðŸš— ç«‹å³å‡ºå‘ (é¢„æµ‹ 30 åˆ†é’ŸåŽåˆ°è¾¾)ï¼šæµé‡ `{flow1:.0f}` veh/hrï¼Œé¢„æœŸè½¦é€Ÿ `{spd1:.1f}` km/h")
            print(f"- â³ æŽ¨è¿Ÿ 15 åˆ†é’Ÿå‡ºå‘ï¼šæµé‡ `{flow2:.0f}` veh/hrï¼Œé¢„æœŸè½¦é€Ÿ `{spd2:.1f}` km/h")
            if 'Success' in key:
                print("- ðŸ’¡ ç³»ç»Ÿå†³ç­–ï¼šå¼ºçƒˆå»ºè®®æ™šç‚¹å‡ºé—¨ï¼Œé¿å¼€å•å‘æ½®æ±æ³¢å³°ï¼Œä½“éªŒæ›´é¡ºç•…ï¼\n")
            elif 'Jam' in key:
                print("- ðŸ’¡ ç³»ç»Ÿå†³ç­–ï¼šé“è·¯é™·å…¥è¿Ÿæ»žçŽ¯æ­»é”ï¼ŒæŽ¨è¿Ÿæ— ç”¨ï¼Œå»ºè®®ç«‹å³å‡ºå‘æˆ–æ¢ä¹˜å…¬å…±äº¤é€šã€‚\n")
            else:
                print("- ðŸ’¡ ç³»ç»Ÿå†³ç­–ï¼šå½“å‰è·¯ç½‘çŠ¶æ€æžä½³ï¼Œéšæ—¶å¯ä»¥å‡ºå‘ã€‚\n")

    # --- ç»˜åˆ¶ Dashboard å¯¹æ¯”å›¾ ---
    print("\nðŸŽ¨ æ­£åœ¨ç”Ÿæˆä¸šåŠ¡ Dashboard å¯è§†åŒ–å›¾è¡¨...")
    os.makedirs('results', exist_ok=True)
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, axes = plt.subplots(1, 3, figsize=(15, 6), sharey=True)
    fig.suptitle('Predictive Departure Scheduling Dashboard\n(Expected Speed Comparison)', fontsize=16,
                 fontweight='bold')

    plot_data = [
        ('A_Shift_Success', 'Scenario A: Shift Recommended', '#2ecc71', 'Shift 15m improves speed'),
        ('B_Persistent_Jam', 'Scenario B: Persistent Jam', '#e74c3c', 'Jam remains severe'),
        ('C_Free_Flow', 'Scenario C: Free Flow', '#3498db', 'Smooth traffic anytime')
    ]

    for i, (key, title, color, desc) in enumerate(plot_data):
        ax = axes[i]
        if scenarios[key]:
            _, _, spd1, _, spd2 = scenarios[key]
            bars = ax.bar(['Depart Now', 'Depart +15 min'], [spd1, spd2], color=['#95a5a6', color], width=0.5)
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.set_ylabel('Expected Speed (km/h)' if i == 0 else '')
            ax.set_ylim(0, 80)

            # æ ‡æ³¨æ•°å€¼
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width() / 2., height + 1,
                        f'{height:.1f} km/h', ha='center', va='bottom', fontweight='bold')
            ax.text(0.5, -0.15, desc, transform=ax.transAxes, ha='center', fontsize=10, style='italic')

    plt.tight_layout(rect=[0, 0.05, 1, 0.95])
    out_path = 'results/business_dashboard.png'
    plt.savefig(out_path, dpi=300)
    plt.close()
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {out_path}")
    print("=" * 60)


if __name__ == "__main__":
    generate_business_dashboard()