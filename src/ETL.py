import pandas as pd
import os
import glob
from tqdm import tqdm

# ================= ğŸ”§ é…ç½®åŒºåŸŸ  =================
# 1. txt file path
RAW_DATA_FOLDER = r'D:\Traffic_Prediction\data'

# 2. æƒ³è¦æå–çš„ç›®æ ‡æ£€æµ‹å™¨ ID
TARGET_STATION_ID = 407204

# 3. è¾“å‡ºæ–‡ä»¶çš„ä¿å­˜è·¯å¾„å’Œåç§°
OUTPUT_FILE = r'D:\Traffic_Prediction\data\station_407204_3months.csv'

# ==============================================================

def run_etl_process():
    print(f"ğŸš€ [ETL Start] å¼€å§‹å¤„ç†æ•°æ®...")
    print(f"   ğŸ“‚ æ•°æ®æºè·¯å¾„: {RAW_DATA_FOLDER}")
    print(f"   ğŸ¯ ç›®æ ‡ç«™ç‚¹ID: {TARGET_STATION_ID}")

    # 1. è·å–æ‰€æœ‰ txt æ–‡ä»¶
    #    glob ä¼šè‡ªåŠ¨åŒ¹é…ç¬¦åˆè§„åˆ™çš„æ–‡ä»¶è·¯å¾„
    search_pattern = os.path.join(RAW_DATA_FOLDER, "d04_text_station_5min_*.txt")
    file_list = sorted(glob.glob(search_pattern))

    if not file_list:
        print("âŒ é”™è¯¯ï¼šåœ¨æŒ‡å®šæ–‡ä»¶å¤¹æ²¡æ‰¾åˆ°ä»»ä½• .txt æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    print(f"   ğŸ“„ å‘ç°æ–‡ä»¶æ•°é‡: {len(file_list)} ä¸ª")

    # 2. å¾ªç¯è¯»å–å¹¶ç­›é€‰
    print(f"   ğŸ”„ æ­£åœ¨é€ä¸ªè¯»å–å¹¶æå–æ•°æ® (è¯·ç¨å€™)...")

    extracted_data_list = []

    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    for file_path in tqdm(file_list, desc="Processing Files", unit="file"):
        try:
            # PeMS åŸå§‹æ•°æ®æ²¡æœ‰è¡¨å¤´ (header=None)
            # æˆ‘ä»¬åªéœ€è¦è¯»å–å…³é”®åˆ—ä»¥èŠ‚çœå†…å­˜ï¼š
            # Col 0: Timestamp (æ—¶é—´)
            # Col 1: Station ID (ç«™ç‚¹ID)
            # Col 9: Total Flow (æµé‡)
            # Col 11: Avg Speed (é€Ÿåº¦)
            # (æ³¨ï¼šåˆ—å·åŸºäº PeMS æ ‡å‡†æ ¼å¼)
            df_temp = pd.read_csv(
                file_path,
                header=None,
                usecols=[0, 1, 9, 11],
                names=['Timestamp', 'Station', 'Flow', 'Speed']
            )

            # ç­›é€‰ç›®æ ‡ç«™ç‚¹
            df_target = df_temp[df_temp['Station'] == TARGET_STATION_ID].copy()

            # å¦‚æœè¿™ä¸€å¤©æœ‰æ•°æ®ï¼Œå°±å­˜èµ·æ¥
            if not df_target.empty:
                extracted_data_list.append(df_target)

        except Exception as e:
            print(f"\nâš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™: {os.path.basename(file_path)} -> {e}")

    # 3. åˆå¹¶æ•°æ®
    if extracted_data_list:
        print(f"   ğŸ§© æ­£åœ¨åˆå¹¶ {len(extracted_data_list)} å¤©çš„æ•°æ®...")
        all_data = pd.concat(extracted_data_list, ignore_index=True)

        # 4. æ•°æ®æ¸…æ´—ä¸æ’åº
        # è½¬æ¢æ—¶é—´æ ¼å¼
        all_data['Timestamp'] = pd.to_datetime(all_data['Timestamp'], format='%m/%d/%Y %H:%M:%S')
        # æŒ‰æ—¶é—´æ’åº
        all_data.sort_values('Timestamp', inplace=True)

        # ç®€å•é¢„è§ˆ
        print("-" * 30)
        print(f"   ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        print(f"   èµ·å§‹æ—¶é—´: {all_data['Timestamp'].min()}")
        print(f"   ç»“æŸæ—¶é—´: {all_data['Timestamp'].max()}")
        print(f"   æ€»è®°å½•æ•°: {len(all_data)} æ¡ (é¢„æœŸçº¦ä¸º 17,000+)")
        print("-" * 30)

        # 5. ä¿å­˜åˆ° CSV
        # index=False è¡¨ç¤ºä¸ä¿å­˜æœ€å·¦è¾¹çš„åºå·åˆ—
        all_data.to_csv(OUTPUT_FILE, index=False)
        print(f"âœ… [Success] æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°: {OUTPUT_FILE}")
        print(f"   ç°åœ¨ä½ å¯ä»¥ç›´æ¥ç”¨ LSTM ä»£ç è¯»å–è¿™ä¸ª CSV æ–‡ä»¶äº†ï¼")

    else:
        print("âŒ è­¦å‘Šï¼šæ‰€æœ‰æ–‡ä»¶ä¸­éƒ½æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡ç«™ç‚¹çš„æ•°æ®ï¼è¯·æ£€æŸ¥ Station ID æ˜¯å¦æ­£ç¡®ã€‚")


if __name__ == '__main__':
    run_etl_process()